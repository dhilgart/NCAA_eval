[tool.poetry]
name = "ncaa-eval"
version = "0.1.0"
description = "Evaluator for self-evaluation of NCAA March Mania Kaggle Competition models"
authors = ["Dan Hilgart <dhilgart@gmail.com>"]
readme = "README.md"
packages = [{include = "ncaa_eval", from = "src"}]

[tool.poetry.dependencies]
python = ">=3.12,<4.0"
pandas = "*"
numpy = "*"
xgboost = "*"
scikit-learn = "*"
networkx = "*"
joblib = "*"
plotly = "*"
streamlit = "*"

[tool.poetry.group.dev.dependencies]
pytest = "*"
pytest-cov = "*"
hypothesis = "*"
mutmut = "*"
ruff = "*"
mypy = "*"
pre-commit = "*"
nox = "*"
commitizen = "*"
check-manifest = "*"
edgetest = "*"
sphinx = "*"
furo = "*"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.mypy]
strict = true
files = ["src/ncaa_eval", "tests"]
follow_imports = "silent"
warn_redundant_casts = true
warn_unused_ignores = true
warn_unused_configs = true

[tool.ruff]
line-length = 110

[tool.ruff.lint]
extend-select = [
    "I",      # Missing required import (auto-fixable)
    "UP",     # Pyupgrade
    "PT",     # flake8-pytest-style rules
    "TID25",  # flake8-tidy-imports rules
    "C90",    # McCabe complexity
    "PLR0911",  # Too many return statements (configured: max-returns = 6)
    "PLR0912",  # Too many branches (configured: max-branches = 12)
    "PLR0913",  # Too many arguments (configured: max-args = 5)
]
ignore = [
    "E501",      # Line too long (handled by formatter)
    "D1",        # Missing docstrings (not yet enforced)
    "D415",      # First line punctuation (not yet enforced)
    "PLR2004",   # Magic value comparison (too aggressive for data science)
]

[tool.ruff.lint.isort]
required-imports = ["from __future__ import annotations"]
combine-as-imports = true
known-first-party = ["tests"]

[tool.ruff.lint.pydocstyle]
convention = "google"

[tool.ruff.lint.mccabe]
# PEP 20: "Simple is better than complex"
# Max cyclomatic complexity per function
max-complexity = 10

[tool.ruff.lint.pylint]
# PEP 20: "Explicit is better than implicit"
# Max arguments per function
max-args = 5
# Max branches in a function
max-branches = 12
# Max return statements in a function
max-returns = 6

[tool.pytest.ini_options]
minversion = "8.0.0"
testpaths = ["tests"]
addopts = "--strict-markers"
norecursedirs = [
    ".*",
    "build",
    "dist",
    "CVS",
    "_darcs",
    "{arch}",
    "*.egg",
    "venv",
    "env",
    "virtualenv",
]
markers = [
    "smoke: Fast smoke tests for pre-commit (< 10 seconds total)",
    "slow: Slow tests excluded from pre-commit (> 5 seconds each)",
    "integration: Integration tests with I/O or external dependencies",
    "property: Hypothesis property-based tests",
    "fuzz: Hypothesis fuzz-based tests for crash resilience",
    "performance: Performance and benchmark tests",
    "regression: Regression tests to prevent bug recurrence",
    "mutation: Tests specifically for mutation testing coverage",
]

[tool.coverage.report]
show_missing = true
exclude_lines = [
    'pragma: no cover',
    'def __repr__',
    'if self\.debug',
    'raise AssertionError',
    'raise NotImplementedError',
    'if 0:',
    'if __name__ == .__main__.:',
]
omit = ['env/*', 'venv/*', '*/virtualenv/*', '*/virtualenvs/*', '*/tests/*']

[tool.commitizen]
name = "cz_conventional_commits"
version = "0.1.0"
tag_format = "$version"
version_files = ["pyproject.toml:version"]

[tool.mutmut]
# Mutation testing targets â€” Tier 1 priority: evaluation module
# Extend as modules are implemented:
# paths_to_mutate = ["src/ncaa_eval/evaluation/", "src/ncaa_eval/model/"]
paths_to_mutate = ["src/ncaa_eval/evaluation/"]
# Exclude file-path-dependent structural smoke tests: they use Path(__file__) to navigate
# to the project root, which resolves incorrectly when mutmut runs tests from mutants/.
# Structural tests don't test evaluation module logic so are not meaningful for mutation testing.
pytest_add_cli_args_test_selection = ["tests/", "-k", "not test_src_directory_structure"]
# Optional: only mutate lines covered by tests (faster runs):
# mutate_only_covered_lines = true
#
# Workflow commands:
#   mutmut run                      # Run mutation testing
#   mutmut results                  # Review results summary
#   mutmut show <mutant-id>         # Inspect a surviving mutant
#   mutmut run --paths-to-mutate=src/ncaa_eval/evaluation/metrics.py  # Target a file
