<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="genindex.html"><link rel="search" title="Search" href="search.html"><link rel="next" title="NCAA Eval Style Guide" href="STYLE_GUIDE.html"><link rel="prev" title="NCAA Eval Documentation" href="index.html">

    <!-- Generated with Sphinx 9.1.0 and Furo 2025.12.19 -->
        <title>User Guide - ncaa_eval 0.9.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=7bdb33bb" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">ncaa_eval 0.9.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  <span class="sidebar-brand-text">ncaa_eval 0.9.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">User Guide:</span></p>
<ul class="current">
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">User Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guides:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="STYLE_GUIDE.html">NCAA Eval Style Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="TESTING_STRATEGY.html">Testing Strategy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Testing Guides:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="testing/conventions.html">Testing Conventions</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing/domain-testing.html">Domain-Specific Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing/execution.html">Test Execution Tiers</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing/quality.html">Test Suite Quality Assurance</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing/test-approach-guide.html">Test Approach Guide: Example-Based vs Property-Based vs Fuzz-Based Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing/test-purpose-guide.html">Test Purpose Guide: Functional, Performance, and Regression Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing/test-scope-guide.html">Test Scope Guide: Unit vs Integration Tests</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference:</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="api/modules.html">ncaa_eval</a><input aria-label="Toggle navigation of ncaa_eval" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="api/ncaa_eval.html">ncaa_eval package</a><input aria-label="Toggle navigation of ncaa_eval package" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="api/ncaa_eval.cli.html">ncaa_eval.cli package</a><input aria-label="Toggle navigation of ncaa_eval.cli package" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.cli.main.html">ncaa_eval.cli.main module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.cli.train.html">ncaa_eval.cli.train module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="api/ncaa_eval.evaluation.html">ncaa_eval.evaluation package</a><input aria-label="Toggle navigation of ncaa_eval.evaluation package" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.evaluation.backtest.html">ncaa_eval.evaluation.backtest module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.evaluation.metrics.html">ncaa_eval.evaluation.metrics module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.evaluation.plotting.html">ncaa_eval.evaluation.plotting module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.evaluation.simulation.html">ncaa_eval.evaluation.simulation module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.evaluation.splitter.html">ncaa_eval.evaluation.splitter module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="api/ncaa_eval.ingest.html">ncaa_eval.ingest package</a><input aria-label="Toggle navigation of ncaa_eval.ingest package" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4 has-children"><a class="reference internal" href="api/ncaa_eval.ingest.connectors.html">ncaa_eval.ingest.connectors package</a><input aria-label="Toggle navigation of ncaa_eval.ingest.connectors package" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l5"><a class="reference internal" href="api/ncaa_eval.ingest.connectors.base.html">ncaa_eval.ingest.connectors.base module</a></li>
<li class="toctree-l5"><a class="reference internal" href="api/ncaa_eval.ingest.connectors.espn.html">ncaa_eval.ingest.connectors.espn module</a></li>
<li class="toctree-l5"><a class="reference internal" href="api/ncaa_eval.ingest.connectors.kaggle.html">ncaa_eval.ingest.connectors.kaggle module</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.ingest.repository.html">ncaa_eval.ingest.repository module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.ingest.schema.html">ncaa_eval.ingest.schema module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.ingest.sync.html">ncaa_eval.ingest.sync module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="api/ncaa_eval.model.html">ncaa_eval.model package</a><input aria-label="Toggle navigation of ncaa_eval.model package" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.model.base.html">ncaa_eval.model.base module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.model.elo.html">ncaa_eval.model.elo module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.model.logistic_regression.html">ncaa_eval.model.logistic_regression module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.model.registry.html">ncaa_eval.model.registry module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.model.tracking.html">ncaa_eval.model.tracking module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.model.xgboost_model.html">ncaa_eval.model.xgboost_model module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="api/ncaa_eval.transform.html">ncaa_eval.transform package</a><input aria-label="Toggle navigation of ncaa_eval.transform package" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.transform.calibration.html">ncaa_eval.transform.calibration module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.transform.elo.html">ncaa_eval.transform.elo module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.transform.feature_serving.html">ncaa_eval.transform.feature_serving module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.transform.graph.html">ncaa_eval.transform.graph module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.transform.normalization.html">ncaa_eval.transform.normalization module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.transform.opponent.html">ncaa_eval.transform.opponent module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.transform.sequential.html">ncaa_eval.transform.sequential module</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.transform.serving.html">ncaa_eval.transform.serving module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="api/ncaa_eval.utils.html">ncaa_eval.utils package</a><input aria-label="Toggle navigation of ncaa_eval.utils package" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="api/ncaa_eval.utils.logger.html">ncaa_eval.utils.logger module</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="_sources/user-guide.md.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="user-guide">
<h1>User Guide<a class="headerlink" href="#user-guide" title="Link to this heading">¶</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#getting-started" id="id1">Getting Started</a></p></li>
<li><p><a class="reference internal" href="#evaluation-metrics" id="id2">Evaluation Metrics</a></p>
<ul>
<li><p><a class="reference internal" href="#log-loss" id="id3">Log Loss</a></p></li>
<li><p><a class="reference internal" href="#brier-score" id="id4">Brier Score</a></p></li>
<li><p><a class="reference internal" href="#roc-auc" id="id5">ROC-AUC</a></p></li>
<li><p><a class="reference internal" href="#expected-calibration-error-ece" id="id6">Expected Calibration Error (ECE)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#model-types" id="id7">Model Types</a></p>
<ul>
<li><p><a class="reference internal" href="#stateful-models" id="id8">Stateful Models</a></p></li>
<li><p><a class="reference internal" href="#stateless-models" id="id9">Stateless Models</a></p></li>
<li><p><a class="reference internal" href="#plugin-registry" id="id10">Plugin Registry</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#interpreting-results" id="id11">Interpreting Results</a></p>
<ul>
<li><p><a class="reference internal" href="#reliability-diagrams" id="id12">Reliability Diagrams</a></p></li>
<li><p><a class="reference internal" href="#calibration-in-plain-language" id="id13">Calibration in Plain Language</a></p></li>
<li><p><a class="reference internal" href="#over-confidence-vs-under-confidence" id="id14">Over-Confidence vs. Under-Confidence</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#tournament-simulation" id="id15">Tournament Simulation</a></p>
<ul>
<li><p><a class="reference internal" href="#monte-carlo-methodology" id="id16">Monte Carlo Methodology</a></p></li>
<li><p><a class="reference internal" href="#bracket-distribution" id="id17">Bracket Distribution</a></p></li>
<li><p><a class="reference internal" href="#expected-points" id="id18">Expected Points</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#tournament-scoring" id="id19">Tournament Scoring</a></p>
<ul>
<li><p><a class="reference internal" href="#standard-scoring-espn-style" id="id20">Standard Scoring (ESPN-style)</a></p></li>
<li><p><a class="reference internal" href="#fibonacci-scoring" id="id21">Fibonacci Scoring</a></p></li>
<li><p><a class="reference internal" href="#seed-difference-bonus" id="id22">Seed-Difference Bonus</a></p></li>
<li><p><a class="reference internal" href="#custom-scoring" id="id23">Custom Scoring</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#dashboard-guide" id="id24">Dashboard Guide</a></p>
<ul>
<li><p><a class="reference internal" href="#lab-backtest-leaderboard" id="id25">Lab: Backtest Leaderboard</a></p></li>
<li><p><a class="reference internal" href="#lab-model-deep-dive" id="id26">Lab: Model Deep Dive</a></p></li>
<li><p><a class="reference internal" href="#presentation-bracket-visualizer" id="id27">Presentation: Bracket Visualizer</a></p></li>
<li><p><a class="reference internal" href="#presentation-pool-scorer" id="id28">Presentation: Pool Scorer</a></p></li>
<li><p><a class="reference internal" href="#game-theory-sliders" id="id29">Game Theory Sliders</a></p></li>
</ul>
</li>
</ul>
</nav>
<section id="getting-started">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">Getting Started</a><a class="headerlink" href="#getting-started" title="Link to this heading">¶</a></h2>
<p>This guide picks up where the <code class="docutils literal notranslate"><span class="pre">README.md</span></code> (project root) left off.
Once you have installed the project and synced data, the typical workflow is:</p>
<ol class="arabic">
<li><p><strong>Sync data</strong> — download NCAA game results from Kaggle (and optionally ESPN):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>sync.py<span class="w"> </span>--source<span class="w"> </span>all<span class="w"> </span>--dest<span class="w"> </span>data/
</pre></div>
</div>
</li>
<li><p><strong>Train a model</strong> — fit a prediction model on historical seasons:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>ncaa_eval.cli<span class="w"> </span>train<span class="w"> </span>--model<span class="w"> </span>elo
python<span class="w"> </span>-m<span class="w"> </span>ncaa_eval.cli<span class="w"> </span>train<span class="w"> </span>--model<span class="w"> </span>xgboost
</pre></div>
</div>
<p>Common options:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Flag</p></th>
<th class="head"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--model</span></code></p></td>
<td><p><em>(required)</em></p></td>
<td><p>Registered model name (<code class="docutils literal notranslate"><span class="pre">elo</span></code>, <code class="docutils literal notranslate"><span class="pre">xgboost</span></code>, or custom)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--start-year</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">2015</span></code></p></td>
<td><p>First training season (inclusive)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--end-year</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">2025</span></code></p></td>
<td><p>Last training season (inclusive)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--data-dir</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">data/</span></code></p></td>
<td><p>Path to synced Parquet files</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--output-dir</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">data/</span></code></p></td>
<td><p>Where to write run artifacts</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--config</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">None</span></code></p></td>
<td><p>JSON file overriding model hyperparameters</p></td>
</tr>
</tbody>
</table>
</div>
</li>
<li><p><strong>Explore results in the dashboard</strong> — launch the Streamlit app:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>streamlit<span class="w"> </span>run<span class="w"> </span>dashboard/app.py
</pre></div>
</div>
<p>The sidebar lets you select a tournament year, model run, and scoring format.
All pages update automatically when you change these filters.</p>
</li>
<li><p><strong>Iterate</strong> — retrain with different hyperparameters, compare on the Leaderboard,
inspect calibration in Model Deep Dive, and use the Bracket Visualizer and
Pool Scorer to turn predictions into bracket picks.</p></li>
</ol>
</section>
<section id="evaluation-metrics">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Evaluation Metrics</a><a class="headerlink" href="#evaluation-metrics" title="Link to this heading">¶</a></h2>
<p>The platform evaluates models on four complementary metrics.
Each captures a different aspect of prediction quality.</p>
<section id="log-loss">
<h3><a class="toc-backref" href="#id3" role="doc-backlink">Log Loss</a><a class="headerlink" href="#log-loss" title="Link to this heading">¶</a></h3>
<p><strong>What it measures:</strong> How well predicted probabilities match actual outcomes, with
heavy penalties for confident wrong predictions.</p>
<p><strong>Formula:</strong></p>
<p>$$\text{Log Loss} = -\frac{1}{N} \sum_{i=1}^{N} \bigl[y_i \ln(p_i) + (1-y_i) \ln(1-p_i)\bigr]$$</p>
<p><strong>Interpretation:</strong></p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-right"><p>Value</p></th>
<th class="head"><p>Meaning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-right"><p>0.0</p></td>
<td><p>Perfect — every prediction was 0% or 100% and correct</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>~0.50</p></td>
<td><p>Good — a well-calibrated model typically lands here</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>0.693</p></td>
<td><p>Random baseline (equivalent to predicting 50% for every game)</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>&gt; 0.693</p></td>
<td><p>Worse than guessing — the model is actively misleading</p></td>
</tr>
</tbody>
</table>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Log Loss is the primary ranking metric in the Kaggle March Machine Learning Mania
competition.  A score of 0.55 means your model is meaningfully better than random
but has room to improve.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Log Loss punishes confident wrong predictions exponentially.  A single game where
you predicted 99% and the other team won adds roughly 4.6 to your loss — far more
than 100 correct predictions at 60% confidence save.</p>
</div>
</section>
<section id="brier-score">
<h3><a class="toc-backref" href="#id4" role="doc-backlink">Brier Score</a><a class="headerlink" href="#brier-score" title="Link to this heading">¶</a></h3>
<p><strong>What it measures:</strong> Mean squared error of probability predictions — a gentler
alternative to Log Loss.</p>
<p><strong>Formula:</strong></p>
<p>$$\text{Brier Score} = \frac{1}{N} \sum_{i=1}^{N} (p_i - y_i)^2$$</p>
<p><strong>Interpretation:</strong></p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-right"><p>Value</p></th>
<th class="head"><p>Meaning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-right"><p>0.0</p></td>
<td><p>Perfect</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>~0.20</p></td>
<td><p>Good model</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>0.25</p></td>
<td><p>Random baseline (predicting 50% for every game)</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>&gt; 0.25</p></td>
<td><p>Worse than guessing</p></td>
</tr>
</tbody>
</table>
</div>
<p>Brier Score is more forgiving of confident wrong predictions than Log Loss because
it uses squared error instead of logarithmic error.  A 99%-confident wrong
prediction adds 0.98 to Brier (vs. 4.6 to Log Loss).</p>
</section>
<section id="roc-auc">
<h3><a class="toc-backref" href="#id5" role="doc-backlink">ROC-AUC</a><a class="headerlink" href="#roc-auc" title="Link to this heading">¶</a></h3>
<p><strong>What it measures:</strong> Discrimination — can the model distinguish winners from
losers?  Equivalently: if you pick a random winning team and a random losing team,
what is the probability the model assigns a higher win probability to the winner?</p>
<p><strong>Formula:</strong> Area under the Receiver Operating Characteristic curve.</p>
<p><strong>Interpretation:</strong></p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-right"><p>Value</p></th>
<th class="head"><p>Meaning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-right"><p>1.0</p></td>
<td><p>Perfect discrimination</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>~0.75</p></td>
<td><p>Good model</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>0.5</p></td>
<td><p>Random — no discrimination ability</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>&lt; 0.5</p></td>
<td><p>Inversely correlated (predicting losers as winners)</p></td>
</tr>
</tbody>
</table>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>ROC-AUC does <strong>not</strong> measure calibration.  A model can have perfect AUC (1.0) but
terrible calibration — e.g., predicting 99% for every game that the favored team
wins and 1% for every upset.  Always pair AUC with calibration metrics (ECE,
reliability diagrams).</p>
</div>
</section>
<section id="expected-calibration-error-ece">
<h3><a class="toc-backref" href="#id6" role="doc-backlink">Expected Calibration Error (ECE)</a><a class="headerlink" href="#expected-calibration-error-ece" title="Link to this heading">¶</a></h3>
<p><strong>What it measures:</strong> How well predicted probabilities correspond to actual win
rates.  If a model says “70% win probability” for 100 games, about 70 should
actually be wins.</p>
<p><strong>Formula:</strong></p>
<p>$$\text{ECE} = \sum_{b=1}^{B} \frac{n_b}{N} \left| \text{acc}(b) - \text{conf}(b) \right|$$</p>
<p>where predictions are binned into $B$ equal-width bins, $n_b$ is the count in bin
$b$, $\text{acc}(b)$ is the observed win rate, and $\text{conf}(b)$ is the mean
predicted probability.</p>
<p><strong>Interpretation:</strong></p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-right"><p>Value</p></th>
<th class="head"><p>Meaning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-right"><p>0.0</p></td>
<td><p>Perfectly calibrated</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>&lt; 0.03</p></td>
<td><p>Excellent calibration</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>0.03–0.08</p></td>
<td><p>Reasonable calibration</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>&gt; 0.10</p></td>
<td><p>Poor calibration — predictions are systematically off</p></td>
</tr>
</tbody>
</table>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>ECE is the single best number for answering “can I trust these probabilities at
face value?”  A low ECE means you can use the model’s probability outputs directly
for bet sizing, pool strategy, and expected-value calculations.</p>
</div>
</section>
</section>
<section id="model-types">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Model Types</a><a class="headerlink" href="#model-types" title="Link to this heading">¶</a></h2>
<p>NCAA_eval supports two model paradigms through a common abstract base class.</p>
<section id="stateful-models">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">Stateful Models</a><a class="headerlink" href="#stateful-models" title="Link to this heading">¶</a></h3>
<p>Stateful models maintain internal ratings that update game-by-game through a season.
They process games <strong>sequentially</strong> — the order matters.</p>
<p><strong>Reference implementation: Elo</strong> (<code class="docutils literal notranslate"><span class="pre">elo</span></code>)</p>
<p>The built-in Elo model tracks a rating for every team.  After each game, ratings
shift based on the outcome and margin of victory:</p>
<ul class="simple">
<li><p>Winners gain rating points; losers lose them</p></li>
<li><p>Upset victories produce larger rating swings</p></li>
<li><p>Ratings mean-revert between seasons (configurable fraction)</p></li>
<li><p>Separate K-factors for early-season, regular-season, and tournament games</p></li>
</ul>
<p><strong>Best for:</strong> Capturing in-season trajectory and momentum.  Elo is simple,
interpretable, and requires no feature engineering.</p>
<p><strong>Key hyperparameters:</strong></p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head text-right"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">initial_rating</span></code></p></td>
<td class="text-right"><p>1500</p></td>
<td><p>Starting rating for new teams</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">k_early</span></code></p></td>
<td class="text-right"><p>56.0</p></td>
<td><p>K-factor for the first 20 games</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">k_regular</span></code></p></td>
<td class="text-right"><p>38.0</p></td>
<td><p>K-factor for regular-season games</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">k_tournament</span></code></p></td>
<td class="text-right"><p>47.5</p></td>
<td><p>K-factor for tournament games</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mean_reversion_fraction</span></code></p></td>
<td class="text-right"><p>0.25</p></td>
<td><p>Fraction pulled toward mean between seasons</p></td>
</tr>
</tbody>
</table>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>You can override any hyperparameter via a JSON config file:
<code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">ncaa_eval.cli</span> <span class="pre">train</span> <span class="pre">--model</span> <span class="pre">elo</span> <span class="pre">--config</span> <span class="pre">my_elo_config.json</span></code></p>
</div>
</section>
<section id="stateless-models">
<h3><a class="toc-backref" href="#id9" role="doc-backlink">Stateless Models</a><a class="headerlink" href="#stateless-models" title="Link to this heading">¶</a></h3>
<p>Stateless models are standard batch-trained classifiers.  They take a feature
matrix as input and produce probability predictions — game order does not matter.</p>
<p><strong>Reference implementation: XGBoost</strong> (<code class="docutils literal notranslate"><span class="pre">xgboost</span></code>)</p>
<p>The built-in XGBoost model uses gradient-boosted decision trees trained on feature
snapshots.  Features are computed by the feature engineering pipeline (Epic 4) and
include team statistics, strength-of-schedule metrics, and graph-based centrality
measures.</p>
<p><strong>Best for:</strong> Combining many feature dimensions for maximum predictive accuracy.
XGBoost typically outperforms Elo when strong features are available.</p>
<p><strong>Key hyperparameters:</strong></p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head text-right"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">n_estimators</span></code></p></td>
<td class="text-right"><p>500</p></td>
<td><p>Maximum number of boosting rounds</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code></p></td>
<td class="text-right"><p>5</p></td>
<td><p>Maximum tree depth</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code></p></td>
<td class="text-right"><p>0.05</p></td>
<td><p>Step size shrinkage</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code></p></td>
<td class="text-right"><p>50</p></td>
<td><p>Stop if validation loss doesn’t improve</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="plugin-registry">
<h3><a class="toc-backref" href="#id10" role="doc-backlink">Plugin Registry</a><a class="headerlink" href="#plugin-registry" title="Link to this heading">¶</a></h3>
<p>Models register themselves via the <code class="docutils literal notranslate"><span class="pre">&#64;register_model(&quot;name&quot;)</span></code> decorator.  To create
a custom model:</p>
<ol class="arabic simple">
<li><p>Subclass <code class="docutils literal notranslate"><span class="pre">Model</span></code> (stateless) or <code class="docutils literal notranslate"><span class="pre">StatefulModel</span></code> (stateful)</p></li>
<li><p>Implement the required methods:</p>
<ul class="simple">
<li><p><strong>Stateless (<code class="docutils literal notranslate"><span class="pre">Model</span></code>):</strong> <code class="docutils literal notranslate"><span class="pre">fit</span></code>, <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>, <code class="docutils literal notranslate"><span class="pre">save</span></code>, <code class="docutils literal notranslate"><span class="pre">load</span></code>, <code class="docutils literal notranslate"><span class="pre">get_config</span></code></p></li>
<li><p><strong>Stateful (<code class="docutils literal notranslate"><span class="pre">StatefulModel</span></code>):</strong> <code class="docutils literal notranslate"><span class="pre">_predict_one</span></code>, <code class="docutils literal notranslate"><span class="pre">update</span></code>, <code class="docutils literal notranslate"><span class="pre">start_season</span></code>, <code class="docutils literal notranslate"><span class="pre">get_state</span></code>,
<code class="docutils literal notranslate"><span class="pre">set_state</span></code>, <code class="docutils literal notranslate"><span class="pre">save</span></code>, <code class="docutils literal notranslate"><span class="pre">load</span></code>, <code class="docutils literal notranslate"><span class="pre">get_config</span></code> — <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> are provided by
the template (<code class="docutils literal notranslate"><span class="pre">_predict_one</span></code> is the per-pair hook that <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> calls)</p></li>
</ul>
</li>
<li><p>Decorate with <code class="docutils literal notranslate"><span class="pre">&#64;register_model(&quot;my_model&quot;)</span></code></p></li>
<li><p>Import the module before training so the decorator fires</p></li>
</ol>
<p>The CLI discovers all registered models automatically:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># List available models</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;from ncaa_eval.model import list_models; print(list_models())&quot;</span>
</pre></div>
</div>
<p>For implementation details, see the <a class="reference internal" href="api/modules.html"><span class="std std-doc">API Reference</span></a>.</p>
</section>
</section>
<section id="interpreting-results">
<h2><a class="toc-backref" href="#id11" role="doc-backlink">Interpreting Results</a><a class="headerlink" href="#interpreting-results" title="Link to this heading">¶</a></h2>
<section id="reliability-diagrams">
<h3><a class="toc-backref" href="#id12" role="doc-backlink">Reliability Diagrams</a><a class="headerlink" href="#reliability-diagrams" title="Link to this heading">¶</a></h3>
<p>A reliability diagram is the visual counterpart to ECE.  It plots predicted
probabilities against observed win rates:</p>
<ul class="simple">
<li><p><strong>X-axis:</strong> Predicted probability (grouped into bins, e.g., 0–10%, 10–20%, …)</p></li>
<li><p><strong>Y-axis:</strong> Actual win rate within each bin</p></li>
<li><p><strong>Perfect calibration line:</strong> The 45° diagonal — if your model says 70%, 70% of
those games should be wins</p></li>
</ul>
<p><strong>How to read the diagram:</strong></p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Pattern</p></th>
<th class="head"><p>Meaning</p></th>
<th class="head"><p>Action</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Points on the diagonal</p></td>
<td><p>Well-calibrated</p></td>
<td><p>No action needed</p></td>
</tr>
<tr class="row-odd"><td><p>Points <strong>above</strong> the diagonal</p></td>
<td><p>Under-confident — actual win rates exceed predictions</p></td>
<td><p>Model could be sharper</p></td>
</tr>
<tr class="row-even"><td><p>Points <strong>below</strong> the diagonal</p></td>
<td><p>Over-confident — predictions overstate win likelihood</p></td>
<td><p>Model needs calibration</p></td>
</tr>
<tr class="row-odd"><td><p>S-shaped curve</p></td>
<td><p>Probabilities are too extreme on both ends</p></td>
<td><p>Retrain with calibration regularization; temperature scaling via Game Theory Sliders (planned feature)</p></td>
</tr>
<tr class="row-even"><td><p>Flat line near 0.5</p></td>
<td><p>Model lacks discrimination</p></td>
<td><p>Improve features or model architecture</p></td>
</tr>
</tbody>
</table>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The Model Deep Dive page in the dashboard shows reliability diagrams with per-year
drill-down.  Compare diagrams across years to check whether calibration is stable
or drifts.</p>
</div>
</section>
<section id="calibration-in-plain-language">
<h3><a class="toc-backref" href="#id13" role="doc-backlink">Calibration in Plain Language</a><a class="headerlink" href="#calibration-in-plain-language" title="Link to this heading">¶</a></h3>
<p>A <strong>well-calibrated</strong> model is one you can take at face value.  When it says
“Duke has a 65% chance of beating UNC,” that means that in a large sample of
similar matchups, Duke would win about 65% of the time.</p>
<p><strong>Why calibration matters for bracket pools:</strong></p>
<ul class="simple">
<li><p><strong>Pool strategy</strong> depends on knowing <em>how likely</em> outcomes are, not just <em>which
team is favored</em></p></li>
<li><p>Expected-point calculations multiply advancement probabilities by scoring weights
— if probabilities are wrong, the strategy is wrong</p></li>
<li><p>An over-confident model will undercount upsets, leading you to pick too much chalk</p></li>
</ul>
</section>
<section id="over-confidence-vs-under-confidence">
<h3><a class="toc-backref" href="#id14" role="doc-backlink">Over-Confidence vs. Under-Confidence</a><a class="headerlink" href="#over-confidence-vs-under-confidence" title="Link to this heading">¶</a></h3>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Type</p></th>
<th class="head"><p>Symptom</p></th>
<th class="head"><p>Reliability Diagram</p></th>
<th class="head"><p>Impact on Brackets</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Over-confident</strong></p></td>
<td><p>Predictions are too extreme (90% when reality is 70%)</p></td>
<td><p>Points below diagonal at high probabilities</p></td>
<td><p>Too much chalk; undervalues upsets</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Under-confident</strong></p></td>
<td><p>Predictions are too moderate (55% when reality is 70%)</p></td>
<td><p>Points above diagonal at high probabilities</p></td>
<td><p>Picks too many upsets; misses value in favorites</p></td>
</tr>
<tr class="row-even"><td><p><strong>Well-calibrated</strong></p></td>
<td><p>Predictions match reality</p></td>
<td><p>Points on or near diagonal</p></td>
<td><p>Bracket strategy reflects true odds</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="tournament-simulation">
<h2><a class="toc-backref" href="#id15" role="doc-backlink">Tournament Simulation</a><a class="headerlink" href="#tournament-simulation" title="Link to this heading">¶</a></h2>
<section id="monte-carlo-methodology">
<h3><a class="toc-backref" href="#id16" role="doc-backlink">Monte Carlo Methodology</a><a class="headerlink" href="#monte-carlo-methodology" title="Link to this heading">¶</a></h3>
<p>The platform simulates the full 64-team NCAA tournament bracket using two methods:</p>
<p><strong>Analytical (Phylourny algorithm):</strong>
Computes exact advancement probabilities via a post-order tree traversal.  Fast and
deterministic — no random sampling needed.  Best for expected-point calculations
where you want precise values.</p>
<p><strong>Monte Carlo simulation:</strong>
Runs thousands of independent tournament simulations (default 10,000).  Each
simulation randomly resolves every game using the model’s pairwise win
probabilities.  Produces:</p>
<ul class="simple">
<li><p><strong>Advancement probabilities</strong> — fraction of simulations each team reaches each
round</p></li>
<li><p><strong>Score distributions</strong> — histogram of total bracket points across all
simulations</p></li>
<li><p><strong>Confidence intervals</strong> — percentile-based ranges for expected outcomes</p></li>
</ul>
</section>
<section id="bracket-distribution">
<h3><a class="toc-backref" href="#id17" role="doc-backlink">Bracket Distribution</a><a class="headerlink" href="#bracket-distribution" title="Link to this heading">¶</a></h3>
<p>When you run a Monte Carlo simulation, the platform computes a full score
distribution for the “chalk bracket” (picking the pre-game favorite in every
matchup).  This answers: “If the model’s probabilities are correct, what range of
scores should I expect?”</p>
<p>Key statistics shown on the Pool Scorer page:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Statistic</p></th>
<th class="head"><p>What It Tells You</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Median</strong></p></td>
<td><p>The score you’d most typically get</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Mean</strong></p></td>
<td><p>Average expected score (weighted by probability)</p></td>
</tr>
<tr class="row-even"><td><p><strong>5th percentile</strong></p></td>
<td><p>Worst-case scenario (lots of upsets)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>95th percentile</strong></p></td>
<td><p>Best-case scenario (mostly chalk)</p></td>
</tr>
<tr class="row-even"><td><p><strong>Std Dev</strong></p></td>
<td><p>How much scores vary across simulated outcomes</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="expected-points">
<h3><a class="toc-backref" href="#id18" role="doc-backlink">Expected Points</a><a class="headerlink" href="#expected-points" title="Link to this heading">¶</a></h3>
<p>Expected Points (EP) combines advancement probabilities with a scoring rule to
answer: “How many bracket points is each team <em>worth</em>?”</p>
<p>$$\text{EP}<em>i = \sum</em>{r=0}^{5} P(\text{team } i \text{ wins round } r) \times \text{points}(r)$$</p>
<p>Teams with high EP are valuable picks — they are likely to advance far <em>and</em> those
rounds are worth many points.  The Bracket Visualizer’s Expected Points table ranks
all 64 teams by EP under your chosen scoring rule.</p>
</section>
</section>
<section id="tournament-scoring">
<h2><a class="toc-backref" href="#id19" role="doc-backlink">Tournament Scoring</a><a class="headerlink" href="#tournament-scoring" title="Link to this heading">¶</a></h2>
<p>The platform supports three built-in scoring systems and lets you define custom
rules.</p>
<section id="standard-scoring-espn-style">
<h3><a class="toc-backref" href="#id20" role="doc-backlink">Standard Scoring (ESPN-style)</a><a class="headerlink" href="#standard-scoring-espn-style" title="Link to this heading">¶</a></h3>
<p>The most common pool format.  Points double each round:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Round</p></th>
<th class="head"><p>Abbrev.</p></th>
<th class="head text-right"><p>Games</p></th>
<th class="head text-right"><p>Points</p></th>
<th class="head text-right"><p>Max Points</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Round of 64</p></td>
<td><p>R64</p></td>
<td class="text-right"><p>32</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-odd"><td><p>Round of 32</p></td>
<td><p>R32</p></td>
<td class="text-right"><p>16</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-even"><td><p>Sweet 16</p></td>
<td><p>S16</p></td>
<td class="text-right"><p>8</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-odd"><td><p>Elite Eight</p></td>
<td><p>E8</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>8</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-even"><td><p>Final Four</p></td>
<td><p>F4</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>16</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-odd"><td><p>Championship</p></td>
<td><p>NCG</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>32</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-even"><td><p><strong>Total</strong></p></td>
<td><p></p></td>
<td class="text-right"><p><strong>63</strong></p></td>
<td class="text-right"><p></p></td>
<td class="text-right"><p><strong>192</strong></p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Worked example:</strong> You correctly pick 20 R64 games, 10 R32 games, 4 S16 games,
2 E8 games, 1 F4 game, and the champion:</p>
<p><code class="docutils literal notranslate"><span class="pre">20×1</span> <span class="pre">+</span> <span class="pre">10×2</span> <span class="pre">+</span> <span class="pre">4×4</span> <span class="pre">+</span> <span class="pre">2×8</span> <span class="pre">+</span> <span class="pre">1×16</span> <span class="pre">+</span> <span class="pre">1×32</span> <span class="pre">=</span> <span class="pre">20</span> <span class="pre">+</span> <span class="pre">20</span> <span class="pre">+</span> <span class="pre">16</span> <span class="pre">+</span> <span class="pre">16</span> <span class="pre">+</span> <span class="pre">16</span> <span class="pre">+</span> <span class="pre">32</span> <span class="pre">=</span> <span class="pre">**120</span> <span class="pre">points**</span></code></p>
</section>
<section id="fibonacci-scoring">
<h3><a class="toc-backref" href="#id21" role="doc-backlink">Fibonacci Scoring</a><a class="headerlink" href="#fibonacci-scoring" title="Link to this heading">¶</a></h3>
<p>Rewards later rounds more steeply than Standard:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Round</p></th>
<th class="head text-right"><p>Points</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>R64</p></td>
<td class="text-right"><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>R32</p></td>
<td class="text-right"><p>3</p></td>
</tr>
<tr class="row-even"><td><p>S16</p></td>
<td class="text-right"><p>5</p></td>
</tr>
<tr class="row-odd"><td><p>E8</p></td>
<td class="text-right"><p>8</p></td>
</tr>
<tr class="row-even"><td><p>F4</p></td>
<td class="text-right"><p>13</p></td>
</tr>
<tr class="row-odd"><td><p>NCG</p></td>
<td class="text-right"><p>21</p></td>
</tr>
<tr class="row-even"><td><p><strong>Total (perfect)</strong></p></td>
<td class="text-right"><p><strong>231</strong></p></td>
</tr>
</tbody>
</table>
</div>
<p>Fibonacci scoring gives more credit for getting later rounds right.  Picking the
champion is worth 21 points (vs. 32 in Standard), but the ratio of
late-round-to-early-round points is higher.</p>
</section>
<section id="seed-difference-bonus">
<h3><a class="toc-backref" href="#id22" role="doc-backlink">Seed-Difference Bonus</a><a class="headerlink" href="#seed-difference-bonus" title="Link to this heading">¶</a></h3>
<p>Standard base points plus an upset bonus equal to the seed difference when the
lower-seeded team wins:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Round</p></th>
<th class="head text-right"><p>Base Points</p></th>
<th class="head"><p>Upset Bonus</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>R64</p></td>
<td class="text-right"><p>1</p></td>
<td><p>+ |seed_winner − seed_loser| if upset</p></td>
</tr>
<tr class="row-odd"><td><p>R32</p></td>
<td class="text-right"><p>2</p></td>
<td><p>+ |seed_winner − seed_loser| if upset</p></td>
</tr>
<tr class="row-even"><td><p>S16</p></td>
<td class="text-right"><p>4</p></td>
<td><p>+ |seed_winner − seed_loser| if upset</p></td>
</tr>
<tr class="row-odd"><td><p>E8</p></td>
<td class="text-right"><p>8</p></td>
<td><p>+ |seed_winner − seed_loser| if upset</p></td>
</tr>
<tr class="row-even"><td><p>F4</p></td>
<td class="text-right"><p>16</p></td>
<td><p>+ |seed_winner − seed_loser| if upset</p></td>
</tr>
<tr class="row-odd"><td><p>NCG</p></td>
<td class="text-right"><p>32</p></td>
<td><p>+ |seed_winner − seed_loser| if upset</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Worked example:</strong> A 12-seed beats a 5-seed in the R64.  You get
1 (base) + 7 (seed diff) = <strong>8 points</strong> for that single game — the same as
getting an Elite Eight pick right under Standard scoring.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Seed-Difference Bonus rewards contrarian picks.  If you are in a large pool where
most people pick chalk, this scoring format lets you differentiate by picking
well-chosen upsets.</p>
</div>
</section>
<section id="custom-scoring">
<h3><a class="toc-backref" href="#id23" role="doc-backlink">Custom Scoring</a><a class="headerlink" href="#custom-scoring" title="Link to this heading">¶</a></h3>
<p>The Pool Scorer page lets you define custom per-round point values.  Check
“Use custom scoring” and enter your pool’s specific point schedule.  This is useful
for pools with non-standard formats (e.g., 1-2-3-5-8-13 or 10-20-40-80-160-320).</p>
</section>
</section>
<section id="dashboard-guide">
<h2><a class="toc-backref" href="#id24" role="doc-backlink">Dashboard Guide</a><a class="headerlink" href="#dashboard-guide" title="Link to this heading">¶</a></h2>
<p>The dashboard has four main pages organized into two sections.</p>
<section id="lab-backtest-leaderboard">
<h3><a class="toc-backref" href="#id25" role="doc-backlink">Lab: Backtest Leaderboard</a><a class="headerlink" href="#lab-backtest-leaderboard" title="Link to this heading">¶</a></h3>
<p><strong>Purpose:</strong> Compare all trained models side-by-side.</p>
<p><strong>What you see:</strong></p>
<ul class="simple">
<li><p><strong>KPI cards</strong> at the top showing the best score for each metric across all runs,
with delta indicators comparing best vs. worst</p></li>
<li><p><strong>Sortable table</strong> with every model run’s Log Loss, Brier Score, ROC-AUC, and ECE</p></li>
<li><p>Color-coded cells (red-yellow-green gradient) for quick visual comparison</p></li>
<li><p>If a year filter is active, metrics are shown for that year only; otherwise,
metrics are averaged across all evaluated years</p></li>
</ul>
<p><strong>How to use it:</strong></p>
<ol class="arabic simple">
<li><p>Select a tournament year in the sidebar (or leave unset for aggregate view)</p></li>
<li><p>Click any row to navigate to the Model Deep Dive for that run</p></li>
</ol>
</section>
<section id="lab-model-deep-dive">
<h3><a class="toc-backref" href="#id26" role="doc-backlink">Lab: Model Deep Dive</a><a class="headerlink" href="#lab-model-deep-dive" title="Link to this heading">¶</a></h3>
<p><strong>Purpose:</strong> Diagnose a single model’s calibration, accuracy, and feature behavior.</p>
<p><strong>What you see:</strong></p>
<ul class="simple">
<li><p><strong>Reliability diagram</strong> — calibration visualization (see
<a class="reference internal" href="#interpreting-results"><span class="xref myst">Interpreting Results</span></a> above)</p></li>
<li><p><strong>Year drill-down</strong> — select a specific fold year to see how calibration varies
over time</p></li>
<li><p><strong>Per-year metric summary</strong> — table of Log Loss, Brier, AUC, and ECE broken out
by year, with gradient coloring</p></li>
<li><p><strong>Feature importance</strong> (XGBoost only) — horizontal bar chart showing which
features contribute most to predictions</p></li>
<li><p><strong>Hyperparameters</strong> — JSON view of the model’s configuration</p></li>
</ul>
<p><strong>How to use it:</strong></p>
<ol class="arabic simple">
<li><p>Click a model run on the Leaderboard, or select a run in the sidebar</p></li>
<li><p>Use the year dropdown to compare calibration across different seasons</p></li>
<li><p>For XGBoost models, check feature importance to understand what drives predictions</p></li>
</ol>
</section>
<section id="presentation-bracket-visualizer">
<h3><a class="toc-backref" href="#id27" role="doc-backlink">Presentation: Bracket Visualizer</a><a class="headerlink" href="#presentation-bracket-visualizer" title="Link to this heading">¶</a></h3>
<p><strong>Purpose:</strong> Turn model predictions into a visual bracket with advancement
probabilities.</p>
<p><strong>What you see:</strong></p>
<ul class="simple">
<li><p><strong>Most-likely bracket</strong> — interactive HTML bracket tree showing predicted winners
at every matchup, with win probabilities displayed</p></li>
<li><p><strong>Advancement heatmap</strong> — color-coded grid showing each team’s probability of
reaching each round</p></li>
<li><p><strong>Pairwise win probabilities</strong> — expandable section where you can pick any two
teams and see the head-to-head probability</p></li>
<li><p><strong>Expected Points table</strong> — all 64 teams ranked by expected points under the
selected scoring rule</p></li>
<li><p><strong>Score distribution</strong> (Monte Carlo only) — histogram of possible bracket scores</p></li>
</ul>
<p><strong>How to use it:</strong></p>
<ol class="arabic simple">
<li><p>Select a model run, tournament year, and scoring format in the sidebar</p></li>
<li><p>Choose “Analytical (exact)” for speed or “Monte Carlo” for score distributions</p></li>
<li><p>If using Monte Carlo, adjust the number of simulations (more = more precise, but
slower)</p></li>
<li><p>Use the Expected Points table to identify high-value picks</p></li>
<li><p>Expand “Pairwise Win Probabilities” to investigate specific matchups</p></li>
</ol>
</section>
<section id="presentation-pool-scorer">
<h3><a class="toc-backref" href="#id28" role="doc-backlink">Presentation: Pool Scorer</a><a class="headerlink" href="#presentation-pool-scorer" title="Link to this heading">¶</a></h3>
<p><strong>Purpose:</strong> Score your bracket against thousands of simulated tournament outcomes
to understand your expected point distribution.</p>
<p><strong>What you see:</strong></p>
<ul class="simple">
<li><p><strong>Scoring configuration</strong> — choose a built-in rule or define custom per-round
points</p></li>
<li><p><strong>Outcome summary</strong> — median, mean, standard deviation, min/max, and percentile
metrics for your bracket’s point total</p></li>
<li><p><strong>Score distribution histogram</strong> — visual distribution of how your bracket would
score across all simulated outcomes</p></li>
<li><p><strong>CSV export</strong> — download your bracket as a CSV file for submission to your pool</p></li>
</ul>
<p><strong>How to use it:</strong></p>
<ol class="arabic simple">
<li><p>Select a model run and tournament year in the sidebar</p></li>
<li><p>Configure your pool’s scoring rules (or use the default Standard scoring)</p></li>
<li><p>Adjust the number of Monte Carlo simulations (10,000 is a good default)</p></li>
<li><p>Click “Analyze Outcomes” to run the simulation</p></li>
<li><p>Review the outcome summary to understand your expected score range</p></li>
<li><p>Download the bracket CSV for your pool submission</p></li>
</ol>
</section>
<section id="game-theory-sliders">
<h3><a class="toc-backref" href="#id29" role="doc-backlink">Game Theory Sliders</a><a class="headerlink" href="#game-theory-sliders" title="Link to this heading">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Game Theory Sliders are a planned feature based on research from Story 7.7.
They are not yet implemented in the dashboard.  This section describes the
intended design.</p>
</div>
<p>Two sliders will allow you to adjust the bracket strategy without retraining:</p>
<p><strong>Upset Aggression</strong> (range: −5 to +5, default: 0)</p>
<p>Controls whether your bracket picks favor chalk (favorites) or chaos (upsets):</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-right"><p>Setting</p></th>
<th class="head text-center"><p>Temperature</p></th>
<th class="head"><p>Effect</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-right"><p>−5</p></td>
<td class="text-center"><p>0.31</p></td>
<td><p>Extreme chalk — nearly every favorite wins</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>−3</p></td>
<td class="text-center"><p>0.50</p></td>
<td><p>Strong chalk — favorites heavily reinforced</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>0</p></td>
<td class="text-center"><p>1.00</p></td>
<td><p>Neutral — model probabilities unchanged</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>+3</p></td>
<td class="text-center"><p>2.00</p></td>
<td><p>Strong chaos — probabilities compress toward 50/50</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>+5</p></td>
<td class="text-center"><p>3.17</p></td>
<td><p>Extreme chaos — nearly every game is a coin flip</p></td>
</tr>
</tbody>
</table>
</div>
<p>Mathematically, this applies a power transform to every win probability:</p>
<p>$$p’ = \frac{p^{1/T}}{p^{1/T} + (1-p)^{1/T}} \quad \text{where } T = 2^{v/3}$$</p>
<p>A probability of exactly 50% is never moved.  Favorites remain favorites — the
transform preserves the ranking of all probabilities.</p>
<p><strong>Seed-Weight</strong> (range: 0% to 100%, default: 0%)</p>
<p>Blends the model’s predictions with historical seed-vs-seed win rates:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-right"><p>Setting</p></th>
<th class="head"><p>Effect</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-right"><p>0%</p></td>
<td><p>Pure model predictions</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>25%</p></td>
<td><p>75% model + 25% historical seed performance</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>50%</p></td>
<td><p>Equal blend of model and seed history</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>100%</p></td>
<td><p>Ignore the model entirely; use historical seed win rates</p></td>
</tr>
</tbody>
</table>
</div>
<p>This is useful when you believe the tournament seeding committee has information
your model doesn’t capture, or when your model makes predictions that diverge
significantly from historical seed performance.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>In a <strong>small pool</strong> (&lt; 10 people), pick chalk — you want the most likely
bracket.  In a <strong>large pool</strong> (50+ people), increase Upset Aggression to
differentiate your bracket from the crowd.</p>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="STYLE_GUIDE.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">NCAA Eval Style Guide</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Home</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2026, Dan Hilgart
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">User Guide</a><ul>
<li><a class="reference internal" href="#getting-started">Getting Started</a></li>
<li><a class="reference internal" href="#evaluation-metrics">Evaluation Metrics</a><ul>
<li><a class="reference internal" href="#log-loss">Log Loss</a></li>
<li><a class="reference internal" href="#brier-score">Brier Score</a></li>
<li><a class="reference internal" href="#roc-auc">ROC-AUC</a></li>
<li><a class="reference internal" href="#expected-calibration-error-ece">Expected Calibration Error (ECE)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#model-types">Model Types</a><ul>
<li><a class="reference internal" href="#stateful-models">Stateful Models</a></li>
<li><a class="reference internal" href="#stateless-models">Stateless Models</a></li>
<li><a class="reference internal" href="#plugin-registry">Plugin Registry</a></li>
</ul>
</li>
<li><a class="reference internal" href="#interpreting-results">Interpreting Results</a><ul>
<li><a class="reference internal" href="#reliability-diagrams">Reliability Diagrams</a></li>
<li><a class="reference internal" href="#calibration-in-plain-language">Calibration in Plain Language</a></li>
<li><a class="reference internal" href="#over-confidence-vs-under-confidence">Over-Confidence vs. Under-Confidence</a></li>
</ul>
</li>
<li><a class="reference internal" href="#tournament-simulation">Tournament Simulation</a><ul>
<li><a class="reference internal" href="#monte-carlo-methodology">Monte Carlo Methodology</a></li>
<li><a class="reference internal" href="#bracket-distribution">Bracket Distribution</a></li>
<li><a class="reference internal" href="#expected-points">Expected Points</a></li>
</ul>
</li>
<li><a class="reference internal" href="#tournament-scoring">Tournament Scoring</a><ul>
<li><a class="reference internal" href="#standard-scoring-espn-style">Standard Scoring (ESPN-style)</a></li>
<li><a class="reference internal" href="#fibonacci-scoring">Fibonacci Scoring</a></li>
<li><a class="reference internal" href="#seed-difference-bonus">Seed-Difference Bonus</a></li>
<li><a class="reference internal" href="#custom-scoring">Custom Scoring</a></li>
</ul>
</li>
<li><a class="reference internal" href="#dashboard-guide">Dashboard Guide</a><ul>
<li><a class="reference internal" href="#lab-backtest-leaderboard">Lab: Backtest Leaderboard</a></li>
<li><a class="reference internal" href="#lab-model-deep-dive">Lab: Model Deep Dive</a></li>
<li><a class="reference internal" href="#presentation-bracket-visualizer">Presentation: Bracket Visualizer</a></li>
<li><a class="reference internal" href="#presentation-pool-scorer">Presentation: Pool Scorer</a></li>
<li><a class="reference internal" href="#game-theory-sliders">Game Theory Sliders</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=39bb1c6d"></script>
    <script src="_static/doctools.js?v=fd6eb6e6"></script>
    <script src="_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="_static/scripts/furo.js?v=46bd48cc"></script>
    </body>
</html>